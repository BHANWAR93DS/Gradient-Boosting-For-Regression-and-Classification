# Gradient-Boosting-For-Regression-and-Classification
Implementation of Gradient Boosting Regression and Classification using scikit-learn on synthetic data. Includes model training, evaluation metrics, and visualizations in a well-documented Jupyter notebook.

This repository contains Jupyter notebooks demonstrating Gradient Boosting and Decision Tree models on synthetic data. The focus is on understanding model behavior, especially overfitting and underfitting.

## üìÅ Notebooks Included
- `Gradient_Boosting_Regression.ipynb`: Fits a Gradient Boosting Regressor on noisy quadratic data. Shows how predictions evolve with boosting stages.
- `Gradient_Boost_Classification_1.ipynb`: Applies Gradient Boosting Classifier and analyzes residuals from predicted probabilities.


## üîç Key Concepts
- Synthetic data generation using NumPy and scikit-learn
- Gradient Boosting: stage-wise learning and prediction refinement
- Residual analysis in classification
- Visual comparison of underfitting vs overfitting
- Simple, clear plots to support model interpretation

## üõ†Ô∏è Libraries Used
- scikit-learn  
- pandas  
- numpy  
- matplotlib  
- seaborn


## üöÄ How to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/BHANWAR93DS/Gradient-Boosting-For-Regression-and-Classification.git



